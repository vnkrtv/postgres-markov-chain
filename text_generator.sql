-- Generate phrase by input phrase
CREATE OR REPLACE FUNCTION generate_phrase(input_phrase text) RETURNS text
    LANGUAGE plpgsql
AS
$$
DECLARE
    phrase      text;
    words_arr   text[];
    state_size  integer;
    init_state  text[];
    phrase_arr  text[];
BEGIN
    state_size := (
        SELECT array_length(state, 1)
        FROM chain_table
        LIMIT 1);
    IF state_size IS NULL THEN
        RAISE EXCEPTION 'Error: chain_table is empty';
    END IF;

    phrase_arr := string_to_array(input_phrase, ' ');
    FOR i IN array_length(phrase_arr, 1) - state_size .. array_length(phrase_arr, 1)
        LOOP
            init_state := array_append(init_state, phrase_arr[i]);
        END LOOP;

    words_arr := chain_walk(init_state);
    phrase := '';
    FOR i IN 1 .. array_length(phrase_arr, 1) - state_size - 1
        LOOP
            phrase := phrase || phrase_arr[i] || ' ';
        END LOOP;
    FOR i IN 1 .. array_length(words_arr, 1)
        LOOP
            phrase := phrase || words_arr[i] || ' ';
        END LOOP;
    RETURN initcap(phrase);
END
$$;

SELECT * FROM chain_table;
CALL train_chain(array ['\nУ многих еще остались радиоприёмники с диапазонами СВ и ДВ, и радиолюбительский интерес к приёму в этих диапазонах также по-прежнему сохраняется. На средних волнах в условиях отсутствия помех (за городом, в парке, на балконе, с внешней антенной или, в крайнем случае, у окна квартиры) в вечернее время принимается много удаленных радиостанций, но днем в эфире слышны только шумы. В диапазоне ДВ радиостанций не осталось совсем.\n\nИсправить положение можно с помощью простого маломощного радиопередатчика, действующего в радиусе нескольких метров. В процессе сборки одной из таких конструкций у автора родилась идея попытаться сделать такой передатчик на базе Arduino.\n\nОсновные требования к устройству: имеющаяся в наличии плата Arduino UNO или Arduino Leonardo, максимальная простота электрической схемы (не сложнее самых простых передатчиков на одном транзисторе) и удовлетворительное для АМ-диапазона качество звучания.\n\nВ качестве несущей для наших целей можно использовать сигнал прямоугольной формы, получить который не составляет труда, а прием вести на одной из гармоник. С учетом малой мощности передатчика, сигналы «лишних» гармоник не будут распространятся далее пределов комнаты и не создадут помех окружающим.\n\nСложности возникают с управлением амплитудой: сигнал на выходах может принимать только два значения, а использование даже простейшего ЦАП добавит в конструкцию десяток резисторов.\n\nЗамечание с забеганием вперед об analogWriteЗаметим, что использовать ШИМ и analogWrite в их классическом варианте не удастся из-за высокой частоты несущей, не менее 150 кГц для нижней границы диапазона ДВ. Хотя именно ШИМ, но использованная в ином качестве, поможет получить решение.\n\nС другой стороны, просто реализуется управление длительностью импульса. Выясним, как этот параметр повлияет на амплитуды входящих в состав сигнала гармоник.\n\nОбозначим  функцию прямоугольного сигнала с периодом , длительностью импульса  и амплитудой A:\n\nВ разложении  в ряд Фурье\n коэффициенты  в силу чётности  равны нулю. Следовательно, амплитуда й гармоники совпадает с коэффициентом \n\nНо  при  и  хорошо приближается , если  мало. Значит, при малых  зависимость амплитуды й гармоники от  близка к линейной, и вместо амплитуды несущей можно изменять длительность импульса, заботясь о том, чтобы она не превышала некоторой достаточно малой величины!\n\nНесложно написать скетч для формирования такого сигнала, но в этом нет необходимости: готовый сигнал нужной нам формы можно получить на выходе с широтно-импульсной модуляцией. При частоте ШИМ 62,5 кГц частота третьей гармоники равна 187.5 кГц, и она попадает в радиовещательный диапазон длинных волн. Достаточно подать на соответствующий выход Arduino сигнал низкой частоты и подключить к нему антенну, остальное сделает ШИМ. Важно лишь, чтобы значение параметра value функции analogWrite не превышало границы, определяемой величиной допустимых искажений. Оценим эту границу.\n\nПусть , где  — длительность импульса в долях периода. Тогда .\nОтносительное отклонение  от линейной функции  \n\nпри . С увеличением  отклонение растёт. Для  и  оно составляет около 10%, что достаточно много. При выборе гармоники более высокого порядка отклонение становится еще больше. Так как при 8 битной ШИМ длительности импульса  соответствует value=255, то для для  необходимо, чтобы value не превышал . Полученная оценка позволяет получить представление о порядке допустимых величин и далее подобрать подходящие значения экспериментально.\n\nИтогом громоздкого блока теории являются простая схема:\n\nи очень простой скетч:\n\nvoid setup() {\n// Параметры ШИМ\nTCCR1A = TCCR1A & 0xe0 | 1;\nTCCR1B = TCCR1B & 0xe0 | 0x09;\n}\n\nint const SHIFT = 8;\nint const SCALE = 8;\n\nvoid loop() {\n  analogWrite(9, (analogRead(A0) - 512) / SCALE + SHIFT);\n}\n\nВ качестве антенны использован отрезок монтажного провода длиной 1 метр. \n\nSHIFT задает значение на выходе ШИМ при отсутствии входного сигнала. В процессе модуляции оно меняется в пределах от 1 до 15, длительность импульса при этом составляет от 1/255 до 15/255 периода.\n\nКонстанта SCALE подобрана экспериментально так, чтобы сигнал с выхода телефона укладывался в допустимые границы значений на выходе ШИМ.\n\nПри подаче на вход устройства синусоиды 1 кГц от ГСС, на выходе приемника, настроенного на частоту 187,5 кГц, получается громкий сигнал неискаженной формы:\n\n\nДальность приема на карманный супергетеродин составляет около полутора метров.\n\nВторой раз в диапазоне ДВ сигнал принимается на частоте 250 кГц. Потеря качества на слух при переходе на четвертую гармонику незаметна. С увеличением номера гармоники искажения растут, но при выбранных параметрах и на девятой гармонике 562,5 кГц, попадающей в нижнюю часть диапазона средних волн, качество остается приемлемым.\n\nУвеличивая (в разумных пределах) значение SHIFT, можно попытаться добиться повышения качества звучания за счет поиска компромисса между увеличением количества уровней дискретизации и ростом искажений. SCALE в этом случае нужно уменьшить, чтобы сохранить коэффициент модуляции. Однако, теряется возможность приёма на более высоких гармониках. Например, эксперимент с SHIFT = 16 и SCALE = 4 показал неплохой результат на частоте 187,5 кГц, но в диапазоне СВ искажения оказались очень большими.\n\nВ итоге получилось простое устройство, не содержащее самодельных катушек индуктивности. К его достоинствам можно отнести стабильность частоты несущей и отсутствие паразитной частотной модуляции, что обычно является проблемой для простейших конструкций.\n\nВ заключение статьи видео с демонстрацией работы микропередатчика. \n\n', '\nПроект: “Абсолютный курс валют”\nВведение\nО проекте\nПроект “Абсолютный курс валют” занимается анализом парных валютных курсов, выделением из них абсолютных валютных курсов и их анализом. \nВ рамках проекта получена методика преобразования от парных курсов к абсолютным валютным курсам. Для этого определена абсолютная валюта ABS. Курсы всех имеющихся валют выражаются в отношении к ABS.\nВ проекте исследуются свойства абсолютных курсов. Исследуются различные применения абсолютных курсов валют.\nЗачем это...?\nНа сегодняшний день уже вышли несколько статей по применению метода абсолютных валютных курсов. Привожу две последние.\nВ статье “Исследование связанности мировых валют через корреляцию абсолютных курсов” описывается одно из применений технологии абсолютных валютных курсов. Дается формальный метод вычисления связи между различными валютами.\nВ статье “Портфельный метод Марковица применительно к валютному рынку” дается описывается недоступная ранее технология оптимизации валютного портфеля.\nНа этих двух применениях исследования не останавливаются. Проверяются другие применения технологии. Если у читателей есть свои видения о прочих возможных применениях их можно писать в обсуждениях к статье. Ссылки на места обсуждений приводятся.\nМетодика получения абсолютных курсов\nДетальное описание технологии приводится в статье “От валютных пар к абсолютным курсам валют”.\nВ основе метода лежит разбор представления парных курсов. Парный валютный курс — это отношение ценности одной валюты к ценности другой. А если ввести некоторую универсальную абсолютную валюту ABS, то имеет место быть следующее преобразование.\n\nПарный валютный курс есть отношение двух абсолютных курсов. \nДля того чтобы получить абсолютные курсы нужно сначала прологарифмировать это уравнение.\n\nСоответственно можно видеть, что логарифмы парных курсов линейно связаны с логарифмами абсолютных курсов валют. И значит можно поискать между ними простое линейное преобразование. Логарифмы абсолютных курсов можно умножать на матрицу прямого преобразования и получать логарифмы парных курсов.\n\nИ стоит ожидать что существует обратное линейное преобразование для перехода от парных курсов к абсолютным.\n\nСоответственно вся методика получения абсолютных курсов записывается следующим образом.\n\nНужно просто логарифмировать парные курсы, умножать их на обратную матрицу и применять экспоненту.\nО проблеме\nВыше было описано как получать абсолютные курсы из парных. Это делается при помощи линейного преобразования логарифмированных парных курсов и возврата через экспоненту.\nПрямое линейное преобразование от абсолютных курсов к парным производится при помощи прямой матрицы. Получить ее весьма просто. Она состоит из нулей, единиц и минус единиц (“0” — нет связи пары и валюты, “+1” — валюта в числителе пары, “-1” — валюта в знаменателе пары). Ниже можно будет ее увидеть.\nНаибольшую проблему представляет получение обратной матрицы (точнее необходимо использовать псевдообратное преобразование). С ее помощью можно перейти от парных курсов к абсолютным. Но получение этой матрицы нетривиально вследствии вырожденности матрицы прямого преобразования. \nВ предыдущей статье дается описание одного метода получения такой матрицы. В статье “Детали перехода от парных (относительных) валютных курсов к абсолютным. Работа над ошибками” раскрывается метод получения абсолютных курсов. В эксперименте мы воспользовались приемом перехода к линейно-независимым компонентам. Таким образом удалось избавится от вырожденности в псевдообратном преобразовании.\nМетод настоящего эксперимента\nВ этой работе предлагается другой метод ухода от вырожденности в матрице прямого преобразования. В настоящее время используются парные курсы которые предоставляет РБЦ. Там 88 пар валют для экспорта. Для них существует следующая матрица прямого преобразования.\n\nБелое в ней нули, синее -1 и красное это единицы. Но она вырожденная. Т.е. от нее не получится обратная матрица.\nПри проведении предыдущего эксперимента удалось заметить что диагонально подобная матрица имеет обратное преобразование. Соответственно было сделано предложение перейти к кросс-курсам и невырожденной матрице преобразования. \nВесь расчет проводился в системе Wolfram Mathematica. Система позволяет получать кросс-курсы прямо внутри системы.\nДетали эксперимента (малый пример)\nВсего имеются 45 валют. Для наглядности сначала рассмотрим случай с малым количеством валют и валютных пар. Расчет доступен по ссылке в облаке Wolfram Cloud.\nСписок валют и валютных пар\nБыли отобраны следующие 10 валют: AUD, CAD, HKD, JPY, SEK, USD, CHF, EUR, CNY, CZK. Из них определили 9 валютных пар: AUD/CAD, CAD/HKD, HKD/JPY, JPY/SEK, SEK/USD, USD/CHF, CHF/EUR, EUR/CNY, CNY/CZK.\nМатрица прямого преобразования\nМатрица прямого преобразования имеет следующий вид.\n\nРасцвеченный вариант выглядит так.\n\nРазмер матрицы — 10х9. Ранг матрицы — 9. Матрица невырожденная. Можно свободно искать обратную к ней.\nМатрица обратного преобразования от парных курсов к абсолютным\nВ результате применения метода псевдообратного преобразования получаем обратную матрицу.\n\nВ расцвеченном виде так.\n\nРазмер обратной матрицы — 9х10.\nПроверка обратной матрицы\nПрежде чем двигаться дальше проверяем полученную матрицу. Для этого обратную матрицу умножим на прямую. Результат видим следующий.\n\nИ в расцвеченном виде.\n\nДействительно получили единичную диагональную матрицу. Значит обратная верна.\nВ предыдущем эксперименте проводили проверку метода получения абсолютных курсов. Для этого из полученных абсолютных курсов восстанавливали парные курсы через матрицу прямого преобразования. Дальше сравнивали восстановленные парные курсы с исходными и смотрели ошибку. В нашем случае ошибка при такой проверке будет в пределах машинной точности.\nПроверка на реальных курсах\nТеперь посмотрим результаты на реальных данных. Возьмем реальные котировки парных валютных кросс-курсов и рассчитаем для них абсолютные курсы.\nБыли взяты ежедневные кросс-курсы за 30 дней с 28.03.2019 по 27.04.2019. \nКурсы валютных пар\nВот матрица парных валютных курсов. Это столбцы парных валютных курсов для следующих пар AUD/CAD, CAD/HKD, HKD/JPY, JPY/SEK, SEK/USD, USD/CHF, CHF/EUR, EUR/CNY, CNY/CZK.\n\nВот график курса для одной из валютных пар.\n\nСредние значения для парных курсов получились следующими.\n\nТеперь попробуем оценить вариативность данных. Для этого используем стандартное отклонение. Но для стандартизации разделим его на среднее значение. Результаты отобразим на диаграмме.\n\nКак можно видеть стандартные отклонения для каждой валютной пары находятся в пределах 0, 2% — 0, 9% от средних значений парных курсов.\nАбсолютные курсы\nТеперь вычисляем для парных абсолютные курсы (методика описана в разделе Методика получения абсолютных курсов). После вычислений получаем следующие ряды данных.\nЭто столбцы абсолютных курсов для следующих валют AUD, CAD, HKD, JPY, SEK, USD, CHF, EUR, CNY, CZK.\n\nПриведем график абсолютного курса одной из валют.\n\nСредние значения для абсолютных курсов следующие.\n\nОценим вариативность абсолютных валютных курсов. \n\nСтандартные отклонения для абсолютных курсов каждой валюты находятся в пределах 0, 2% — 0, 7% от средних значений абсолютных курсов. И это согласуется с данными для валютных пар.\nРезультаты на всех валютах\nТеперь рассмотрим результаты на всех имеющихся валютах. Исходник расчета доступен по ссылке.\nСписок валют и валютных пар\nПолный перечень содержит следующие 45 валют: AUD, CAD, HKD, JPY, SEK, USD, CHF, EUR, CNY, CZK, GBP, ILS, NOK, NZD, RUB, SGD, ZAR, AED, ARS, BRL, CLP, COP, DKK, EGP, HUF, IDR, INR, ISK, KRW, KWD, KZT, MXN, MYR, PEN, PHP, PKR, PLN, QAR, RON, SAR, THB, TRY, TWD, UAH, VND. Для них выбраны следующие 44 валютные пары: AUD/CAD, CAD/HKD, HKD/JPY, JPY/SEK, SEK/USD, USD/CHF, CHF/EUR, EUR/CNY, CNY/CZK, CZK/GBP, GBP/ILS, ILS/NOK, NOK/NZD, NZD/RUB, RUB/SGD, SGD/ZAR, ZAR/AED, AED/ARS, ARS/BRL, BRL/CLP, CLP/COP, COP/DKK, DKK/EGP, EGP/HUF, HUF/IDR, IDR/INR, INR/ISK, ISK/KRW, KRW/KWD, KWD/KZT, KZT/MXN, MXN/MYR, MYR/PEN, PEN/PHP, PHP/PKR, PKR/PLN, PLN/QAR, QAR/RON, RON/SAR, SAR/THB, THB/TRY, TRY/TWD, TWD/UAH, UAH/VND.\nМатрица прямого преобразования\nПолучили матрицу прямого преобразования размером 45 на 44. Ранг у нее равен 44.\n\nМатрица обратного преобразования\nОбратная матрица получилась в результате применения обратно псевдопреобразования. Размер матрицы 44 на 45. \n\nПроверка обратной матрицы\nПосле умножения обратной матрицы на прямую получили единичную матрицу.\n\nПроверка на реальных курсах\nПодгрузили 44 парных валютных кросс-курса. Пример одного приводим на следующем графике.\n\nВот данные о средних значениях курсов для каждой валютной пары.\nAUD/CAD 0.951638\nCAD/HKD 5.8662\nHKD/JPY 14.2202\nJPY/SEK 0.0834375\nSEK/USD 0.107433\nUSD/CHF 1.00544\nCHF/EUR 0.885125\nEUR/CNY 7.54636\nCNY/CZK 3.40522\nCZK/GBP 0.0335481\nGBP/ILS 4.69022\nILS/NOK 2.38106\nNOK/NZD 0.173451\nNZD/RUB 43.5338\nRUB/SGD 0.0209621\nSGD/ZAR 10.4641\nZAR/AED 0.259015\nAED/ARS 11.7136\nARS/BRL 0.0907021\nBRL/CLP 171.256\nCLP/COP 4.72058\nCOP/DKK 0.00210715\nDKK/EGP 2.60095\nEGP/HUF 16.5291\nHUF/IDR 49.5307\nIDR/INR 0.00490364\nINR/ISK 1.73912\nISK/KRW 9.44975\nKRW/KWD 0.000266945\nKWD/KZT 1248.05\nKZT/MXN 0.050062\nMXN/MYR 0.216251\nMYR/PEN 0.803967\nPEN/PHP 15.7631\nPHP/PKR 2.71475\nPKR/PLN 0.0269842\nPLN/QAR 0.954411\nQAR/RON 1.16298\nRON/SAR 0.885697\nSAR/THB 8.48908\nTHB/TRY 0.179564\nTRY/TWD 5.39876\nTWD/UAH 0.871089\nUAH/VND 863.675\nДля каждой валютной пары смотрим вариативность как и в эксперименте выше.\n\nСтандартное отклонение для всех валютных пар находится в пределах от 0,2% до 2,5% от среднего значения.\nПосле пересчета получаем абсолютные курсы. Вот график абсолютного курса одной из валют.\n\nСредние значения абсолютных курсов получилось следующими.\nAUD 12.4626\nCAD 13.096\nHKD 2.23247\nJPY 0.156996\nSEK 1.88165\nUSD 17.5149\nCHF 17.4213\nEUR 19.6824\nCNY 2.60821\nCZK 0.765955\nGBP 22.832\nILS 4.86814\nNOK 2.04455\nNZD 11.7884\nRUB 0.270822\nSGD 12.9197\nZAR 1.23485\nAED 4.76765\nARS 0.407218\nBRL 4.49018\nCLP 0.0262207\nCOP 0.0055548\nDKK 2.63619\nEGP 1.01359\nHUF 0.0613224\nIDR 0.00123809\nINR 0.25249\nISK 0.145194\nKRW 0.0153652\nKWD 57.5605\nKZT 0.0461203\nMXN 0.921362\nMYR 4.26106\nPEN 5.30007\nPHP 0.336241\nPKR 0.123862\nPLN 4.59025\nQAR 4.8096\nRON 4.1356\nSAR 4.66938\nTHB 0.550046\nTRY 3.06473\nTWD 0.567676\nUAH 0.651731\nVND 0.000754602\nВариативность абсолютных курсов можно оценить по диаграмме.\n\nСтандартное отклонение всех абсолютных курсов находится в пределах от 0,2% до 2,5% от среднего значения. Что согласуется с данными валютных пар.\nВыводы\nЭксперимент с получением абсолютных курсов из парных кросс-курсов удался. Получен новый метод расчета абсолютных курсов. Метод работает и легко применим. Для дальнейших исследований достаточно легко получать абсолютные курсы.\nТочность метода ограничена лишь точностью выдаваемых кросс-курсов.\nК сожалению открытых источников кросс-курсов обнаружить в сети не получается. И соответственно не получится этот метод применить на сайте. Но при первичном сравнении абсолютных курсов с сайта и полученных в настоящем эксперименте различия были выявлены лишь в четвертом знаке после запятой. Детальное сравнение проведем в следующих работах.\nПоследнюю версию настоящей статьи в PDF формате можно скачать по ссылке.\nЕнин А.В.\nОренбург.\n02.05.2019', '\n\nДинамический ремаркетинг (dynrem) в myTarget — это технология направленной рекламы, использующая информацию о действиях пользователей на сайтах и в мобильных приложениях рекламодателей. Например, в интернет-магазине пользователь просмотрел страницы товаров или добавил их в корзину, и myTarget использует эти события для показа рекламы именно тех товаров и услуг, к которым человек уже проявлял ранее интерес. Сегодня я подробнее расскажу о механизме генерирования неперсональных, то есть item2item-рекомендаций, которые позволяют разнообразить и дополнить рекламную выдачу.\n\nВ качестве клиентов для dynrem myTarget выступают в основном интернет-магазины, у которых может быть один или несколько списков товаров. При построении рекомендаций пару «магазин — список товаров» нужно учитывать как обособленную единицу. Но для простоты дальше будем использовать просто «магазин». Если говорить о размерности задачи на входе, то рекомендации нужно строить примерно для тысячи магазинов, причем количество товаров может варьироваться от нескольких тысяч до миллионов.\n\nСистема рекомендаций для dynrem должна удовлетворять таким требованиям:\n\n\nБаннер содержит товары, которые максимизируют его CTR.\nРекомендации строятся в оффлайн-режиме в течение заданного времени.\nАрхитектура системы должна быть гибкой, масштабируемой, устойчивой и работать в условиях «холодного старта».\n\nОтметим, что из требования построения рекомендаций за фиксированное время и описанных начальных условий (будем оптимистично полагать, что число магазинов возрастает) естественно возникает требование экономного использования машинных ресурсов.\n\nРаздел 2 содержит теоретические основы для построения рекомендательных систем, в разделах 3 и 4 рассматривается практическая сторона вопроса, а в разделе 5 подводится общий итог.\n\nОсновные понятия\nРассмотрим задачу построения рекомендательной системы для одного магазина и перечислим основные математические подходы.\n\nSingular Value Decomposition (SVD)\nПопулярным подходом к построению рекомендательных систем является подход на основе сингулярного разложения (SVD). Матрицу рейтингов  представляют в виде произведения двух матриц  и  так, чтобы , тогда оценка рейтинга пользователя  для товара  представляется в виде  [1], где элементы скалярного произведения являются векторами размерности (основной параметр модели). Эта формула служит основой для других SVD-моделей. Задача нахождения  и  сводится к оптимизации функционала:\n\n(2.1)\n\nгде  — функция ошибки (например, RMSE как в соревновании Netflix),  — регуляризация, а суммирование идет по парам, для которых известен рейтинг. Перепишем выражение (2.1) в явном виде:\n\n(2.2)\n\nЗдесь ,  — коэффициенты L2-регуляризации для представлений пользователя  и товара  соответственно. Базовая модель для соревнования Netflix имела вид:\n\n(2.3)\n\n(2.4)\n\nгде ,  и  — смещения для рейтинга, пользователя и товара соответственно. Модель (2.3) — (2.4) можно улучшить, добавив в неё неявное предпочтение пользователя. На примере соревнования Netflix явным откликом является балл, поставленный пользователем фильму «по нашей просьбе», а неявным откликом выступает прочая информация о «взаимодействии пользователя с товаром» (просмотр фильма, его описания, рецензий на него; т.е. неявный отклик не даёт прямой информации о рейтинге фильма, но при этом указывает на заинтересованность). Учёт неявного отклика реализован в модели SVD++:\n\n(2.5)\n \nгде  — набор объектов, с которыми неявно взаимодействовал пользователь,  — представление размерности  для объекта из .\n\nFactorization Machines (FM)\nКак видно на примерах с различными SVD-моделями, одна модель отличается от другой набором слагаемых, входящих в формулу оценки. При этом расширение модели каждый раз представляет из себя новую задачу. Мы хотим, чтобы такие изменения (например, добавление нового вида неявного отклика, учёт временных параметров) можно было легко реализовать, не меняя код реализации модели. Модели (2.1) — (2.5) можно представить в удобной универсальной форме, используя следующую параметризацию. Представим пользователя и товар в виде набора признаков:\n \n(2.6) \n\n\n(2.7)\n\n\n\nРис. 1: Пример матрицы признаков в случае CF.\n\nНапример, в случае коллаборативной фильтрации (CF), когда используются только данные о взаимодействии пользователей и товаров, векторы признаков имеют вид one-hot-кода (Рис. 1). Введём вектор , тогда задача рекомендации сводится к задачам регрессии с целевой переменной :\n\n\nЛинейная модель:\n(2.8)\n\nPoly2:\n(2.9)\n\nFM:\n(2.10)\n\n\nгде  — параметры модели,  — векторы размерности , представляющие признак  в латентном пространстве,  и  — количество признаков пользователя и товара соответственно. В качестве признаков помимо one-hot-кодов могут выступать контентные признаки (Content-based, CB) (Рис. 2), например, векторизованные описания товаров и профилей пользователей.\n\n\nРис. 2: Пример расширенной матрицы признаков.\n\nМодель FM, введенная в [2], является обобщением для (2.1) — (2.5), (2.8), (2.10). Суть FM в том, что она учитывает парное взаимодействия признаков с помощью скалярного произведения , а не с помощью параметра . Преимущество FM относительно Poly2 состоит в существенном уменьшении количества параметров: для векторов  нам потребуется  параметров, а для  потребуется  параметров. При  и  больших порядков первый подход использует значительно меньше параметров.\n\nОбратим внимание: если в обучающей выборке отсутствует конкретная пара , то соответствующее слагаемое с  в Poly2 не влияет на обучение модели, и оценка рейтинга формируется только по линейной части. Однако подход (2.10) позволяет устанавливать связи через другие признаки. Иначе говоря, данные об одном взаимодействии помогают оценить параметры признаков, не входящих в этот пример.\n\nНа основе FM реализуется так называемая гибридная модель, в которой к CF-признакам добавляются CB-признаки. Она позволяет решить проблему холодного старта, а также учитывает пользовательские предпочтения и позволяет делать персональные рекомендации.\n\nLightFM\nВ популярной реализации FM сделан акцент на разделение между признаками пользователя и товара. В качестве параметров модели выступают матрицы  и  представления пользовательских и товарных признаков:\n\n(2.11)\n\nа также смещения . Используя представления пользователя и товара:\n \n(2.12)\n\n(2.13)\n\nполучаем рейтинг пары :\n \n(2.14)\n\nФункции потерь\nВ нашем случае необходимо отранжировать товары для конкретного пользователя так, чтобы более релевантный товар имел больший рейтинг, чем менее релевантный. В LightFM реализовано несколько функций потерь:\n \n\nLogistic представляет собой реализацию, требующую негатив, который явным образом не представлен в большинстве задач.\nBPR [3] заключается в максимизации разности рейтингов между позитивным и негативным примерами для конкретного пользователя. Негатив получают с помощью бутстрэп-сэмплирования. Функционал качества, используемый в алгоритме, аналогичен ROC-AUC.\nWARP [4] отличается от BPR методом сэмплирования негативных примеров и функцией потерь, которая тоже является ранжирующей, но при этом оптимизирует топ рекомендаций для пользователя.\n\nПрактическая реализация\nДля построения рекомендаций в течение заданного времени используется параллельная реализация на Spark. Для каждого магазина запускается независимая задача, исполнение которой контролируется luigi.\n\nПрепроцессинг данных\nПрепроцессинг данных выполняется автоматически масштабируемыми средствами Spark SQL. Отобранные в финальную модель признаки — текстовые описания товаров и каталогов со стандартными преобразованиями.\n\nЧто нам помогало при взаимодействии со Spark:\n\n\nПартицирование подготовленных данных (матрицы взаимодействий пользователей и товаров, признаки для них) по магазинам. Это позволяет на этапе обучения экономить время на чтении данных из HDFS. В противном случае каждой задаче приходится считывать данные в память Spark и фильтровать их по ID магазина.\nСохранение/получение данных в/из Spark мы делаем частями. Это связано с тем, что в процессе любого из этих действий данные загружаются в память JVM. Почему просто не увеличить память для JVM? Во-первых, тогда уменьшается доступная для обучения модели память, а во-вторых, не нужно хранить что-либо в JVM, она выступает в данном случае как временное хранилище.\n\nОбучение модели\nМодель для каждого магазина обучается в своем Spark-контейнере, благодаря чему можно одновременно запускать произвольное количество задач для магазинов, ограниченное только ресурсами кластера.\n\nВ LightFM отсутствуют механизмы ранней остановки, следовательно, мы тратим лишние ресурсы на дополнительные итерации обучения, когда прироста целевой метрики нет. Мы выбрали в качестве метрики AUC, взаимосвязь которого с CTR подтверждается экспериментально.\n\nОбозначим:\n\n — все известные нам взаимодействия между пользователями и товарами, то есть пары ,\n — множество всех товаров ,\n — множество всех пользователей .\nДля конкретного пользователя  также введем  — множество товаров, с которыми взаимодействовал пользователь. AUC можно вычислить следующим образом [ref]:\n\n(3.1)\n\n(3.2)\n\nВ формуле (3.1) нам нужно посчитать рейтинг для всех возможных пар  ( фиксировано), а также сравнить рейтинг для элементов из  с рейтингами из . Учитывая, что пользователь взаимодействует с мизерной частью ассортимента, сложность расчёта составляет . При этом одна эпоха обучения FM обходится нам в .\n\nПоэтому мы модифицировали расчет AUC. Во-первых, следует разбить выборку на тренировочную  и валидационную , причем . Далее мы с помощью сэмплирования формируем множество пользователей для валидации . Для пользователя  из  элементами позитивного класса будем считать множество , аналогичное . В качестве элементов негативного класса возьмем подвыборку  так, чтобы в неё не попали элементы из . Размер подвыборки можно брать пропорциональным размеру , то есть . Тогда формулы (3.1), (3.2) для расчета AUC изменятся:\n\n(3.3)\n\n(3.4)\n\nВ итоге получаем константное время на расчет AUC, так как берём только фиксированную часть пользователей, и множества  и  имеют небольшой размер. Процесс обучения для магазина останавливается после того, как AUC (3.4) перестает улучшаться.\n\nПоиск похожих объектов\nВ рамках задачи item2item необходимо выбрать для каждого товара  (или максимально похожих на него товаров) такие, которые максимизируют кликабельность баннера. Наше допущение: кандидатов для баннера нужно считать из top- ближайших в пространстве эмбеддингов. Мы протестировали следующие методы расчёта «ближайших соседей»: Scala + Spark, ANNOY, SCANNs, HNSW. \n \n\nУ связки Scala + Spark для магазина с 500 тыс. объектов подсчёт честной косинусной метрики занял 15 минут и значительный объём ресурсов кластера, в связи с чем мы протестировали аппроксимальные методы поиска ближайших соседей. При исследовании метода SCANNs варьировались следующие параметры: bucketLimit, shouldSampleBuckets, NumHashes и setSignatureLength, но результаты получились неудовлетворительными по сравнению с остальными методами (в бакеты попадали сильно различающиеся объекты). Алгоритмы ANNOY и HNSW показали результаты, сравнимые с честным косинусом, но отработали значительно быстрее. \n\n\n\n\n200к товаров\n500к товаров\n2.2м товаров\n\n\nАлгоритм\nANNOY\nHNSW\nANNOY\nHNSW\nANNOY\nHNSW\n\n\nвремя построения\nиндекса (сек)\n59.45\n8.64\n258.02\n25.44\n1190.81\n90.45\n\n\nобщее время (сек)\n141.23\n14.01\n527.76\n43.38\n2081.57\n150.92\n\n\n\nВ связи с тем, что быстрее всех алгоритмов отработал HNSW, на нём мы и решили остановится.\nПоиск ближайших соседей мы также осуществляем в Spark-контейнере и записываем результат в Hive с соответствующим партицированием.\n\nЗаключение\nНапомним: WARP мы используем для обучения модели, AUC — для ранней остановки, а финальная оценка качества проводится с помощью А/Б-теста на живом трафике.\n\nМы полагаем, что в этом месте — в организации эксперимента и подборке оптимального состава баннера — заканчивается data и начинается science. Здесь мы учимся определять, имеет ли смысл показать рекомендации для товаров, на которые сработал ретаргетинг; сколько именно рекомендаций показать; сколько просмотренных товаров, и т.д. Об этом мы расскажем в следующих статьях.\n\nДальнейшие улучшения алгоритма — поиск универсальных эмбеддингов, которые позволят поместить товары всех магазинов в одно пространство — мы проводим в рамках парадигмы, описанной в начале статьи.\n\nСпасибо за внимание!\n\nЛитература\n[ 1 ] Ricci F., Rokach L., Shapira B. Introduction to recommender systems handbook\n//Recommender systems handbook. — Springer, Boston, MA, 2011. — С. 147160.\n\n[ 2 ] Rendle S. Factorization machines //2010 IEEE International Conference on Data Mining. — IEEE, 2010. — С. 995-1000.\n\n[ 3 ] Rendle S. et al. BPR: Bayesian personalized ranking from implicit feedback\n//Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence.\n— AUAI Press, 2009. — С. 452-461.\n\n[ 4 ] Weston J., Bengio S., Usunier N. Wsabie: Scaling up to large vocabulary image annotation //Twenty-Second International Joint Conference on Artificial Intelligence. — 2011.'], 3);